{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchaudio\n",
        "from transformers import Wav2Vec2Model, Wav2Vec2Config\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "\n",
        "# 1. Определение модели Few-Shot генератора\n",
        "class FewShotGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Инициализация Wav2Vec2 с правильной конфигурацией\n",
        "        config = Wav2Vec2Config.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "        self.encoder = Wav2Vec2Model(config)\n",
        "\n",
        "        # Загрузка предобученных весов\n",
        "        state_dict = torch.hub.load_state_dict_from_url(\n",
        "            \"https://huggingface.co/facebook/wav2vec2-base-960h/resolve/main/pytorch_model.bin\"\n",
        "        )\n",
        "       # self.encoder.load_state_dict(state_dict)\n",
        "\n",
        "        # Адаптер\n",
        "        self.adapter = nn.Sequential(\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "\n",
        "        # Простой генератор (в реальности используется диффузионная модель)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 16000)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Нормализация входа\n",
        "        x = (x - x.mean()) / (x.std() + 1e-8)\n",
        "\n",
        "        # Извлечение признаков\n",
        "        outputs = self.encoder(x.unsqueeze(0))\n",
        "        features = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "        # Адаптация\n",
        "        sound_profile = self.adapter(features)\n",
        "\n",
        "        # Генерация\n",
        "        return self.generator(sound_profile)\n",
        "\n",
        "# 2. Инициализация модели\n",
        "model = FewShotGenerator()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 3. Подготовка данных\n",
        "def load_audio_samples(num_samples=3, duration=1.0, sr=16000):\n",
        "    \"\"\"Генерация примеров звуков (в реальности загружаются из файлов)\"\"\"\n",
        "    samples = []\n",
        "    for i in range(num_samples):\n",
        "        # Генерация тона с разной частотой\n",
        "        freq = 220 + i * 100  # 220 Гц, 320 Гц, 420 Гц\n",
        "        t = torch.linspace(0, duration, int(sr * duration))\n",
        "        sample = 0.5 * torch.sin(2 * np.pi * freq * t)\n",
        "        samples.append(sample)\n",
        "    return samples\n",
        "\n",
        "samples = load_audio_samples()\n",
        "\n",
        "# 4. Обучение (быстрая адаптация)\n",
        "for epoch in range(10):\n",
        "    epoch_loss = 0\n",
        "    for sample in samples:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Добавляем немного шума для разнообразия\n",
        "        noisy_sample = sample + 0.01 * torch.randn_like(sample)\n",
        "\n",
        "        output = model(noisy_sample)\n",
        "        loss = nn.MSELoss()(output, sample)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(samples):.4f}\")\n",
        "\n",
        "# 5. Генерация нового звука\n",
        "with torch.no_grad():\n",
        "    # Используем один из примеров для контекста\n",
        "    input_audio = samples[0]\n",
        "    generated = model(input_audio)\n",
        "\n",
        "    # Сохранение результата\n",
        "    sf.write(\"generated.wav\", generated.numpy(), 16000)\n",
        "    print(\"Аудио сохранено как generated.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "urW5UDBrbKeg",
        "outputId": "4e483c7d-3a46-4756-9abe-c7be2bb4400a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([16000])) that is different to the input size (torch.Size([1, 16000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.1286\n",
            "Epoch 2, Loss: 0.1369\n",
            "Epoch 3, Loss: 0.1156\n",
            "Epoch 4, Loss: 0.1183\n",
            "Epoch 5, Loss: 0.1048\n",
            "Epoch 6, Loss: 0.1031\n",
            "Epoch 7, Loss: 0.1295\n",
            "Epoch 8, Loss: 0.0900\n",
            "Epoch 9, Loss: 0.1067\n",
            "Epoch 10, Loss: 0.0949\n",
            "Epoch 11, Loss: 0.0909\n",
            "Epoch 12, Loss: 0.0882\n",
            "Epoch 13, Loss: 0.0915\n",
            "Epoch 14, Loss: 0.1180\n",
            "Epoch 15, Loss: 0.0900\n",
            "Epoch 16, Loss: 0.0909\n",
            "Epoch 17, Loss: 0.0881\n",
            "Epoch 18, Loss: 0.0867\n",
            "Epoch 19, Loss: 0.0873\n",
            "Epoch 20, Loss: 0.0873\n",
            "Epoch 21, Loss: 0.0836\n",
            "Epoch 22, Loss: 0.0860\n",
            "Epoch 23, Loss: 0.0897\n",
            "Epoch 24, Loss: 0.0932\n",
            "Epoch 25, Loss: 0.0862\n",
            "Epoch 26, Loss: 0.0911\n",
            "Epoch 27, Loss: 0.0843\n",
            "Epoch 28, Loss: 0.0846\n",
            "Epoch 29, Loss: 0.0840\n",
            "Epoch 30, Loss: 0.0867\n",
            "Epoch 31, Loss: 0.0883\n",
            "Epoch 32, Loss: 0.0855\n",
            "Epoch 33, Loss: 0.0848\n",
            "Epoch 34, Loss: 0.0845\n",
            "Epoch 35, Loss: 0.0861\n",
            "Epoch 36, Loss: 0.0844\n",
            "Epoch 37, Loss: 0.0843\n",
            "Epoch 38, Loss: 0.0842\n",
            "Epoch 39, Loss: 0.0841\n",
            "Epoch 40, Loss: 0.0852\n",
            "Epoch 41, Loss: 0.0847\n",
            "Epoch 42, Loss: 0.0846\n",
            "Epoch 43, Loss: 0.0842\n",
            "Epoch 44, Loss: 0.0984\n",
            "Epoch 45, Loss: 0.0845\n",
            "Epoch 46, Loss: 0.0842\n",
            "Epoch 47, Loss: 0.0842\n",
            "Epoch 48, Loss: 0.0840\n",
            "Epoch 49, Loss: 0.0827\n",
            "Epoch 50, Loss: 0.0871\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LibsndfileError",
          "evalue": "Error opening 'generated.wav': Format not recognised.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-1558148035.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Сохранение результата\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generated.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Аудио сохранено как generated.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(file, data, samplerate, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     with SoundFile(file, 'w', samplerate, channels,\n\u001b[0m\u001b[1;32m    364\u001b[0m                    \u001b[0msubtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                    compression_level, bitrate_mode) as f:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0;31m# get the actual error code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;31m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'generated.wav': Format not recognised."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    # Используем один из примеров для контекста\n",
        "    input_audio = samples[0]\n",
        "    generated = model(input_audio)\n",
        "    print(generated.shape)\n",
        "    torchaudio.save(\n",
        "    \"generated.wav\",\n",
        "    generated,\n",
        "    sample_rate=16000,  # Частота дискретизации\n",
        "    bits_per_sample=16  # 16 бит (стандарт для WAV)\n",
        ")\n",
        "\"\"\"    # Сохранение результата\n",
        "    sf.write(\"generated.wav\", generated.numpy(), 16000)\n",
        "    print(\"Аудио сохранено как generated.wav\")\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lfTtO99Mcq43",
        "outputId": "9bc2202c-9dc9-4674-a960-4b4d88daf3f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    # Сохранение результата\\n    sf.write(\"generated.wav\", generated.numpy(), 16000)\\n    print(\"Аудио сохранено как generated.wav\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}