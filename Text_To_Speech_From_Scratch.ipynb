{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 1942970,
          "sourceType": "datasetVersion",
          "datasetId": 1159053
        },
        {
          "sourceId": 5982931,
          "sourceType": "datasetVersion",
          "datasetId": 3429100
        },
        {
          "sourceId": 8843146,
          "sourceType": "datasetVersion",
          "datasetId": 5322378
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "mathurinache_the_lj_speech_dataset_path = kagglehub.dataset_download('mathurinache/the-lj-speech-dataset')\n",
        "tttzof351_ljspeech_meta_path = kagglehub.dataset_download('tttzof351/ljspeech-meta')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "t4G_qbGzAmGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a66154-261e-44f9-cf1e-5d56d154171a"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mathurinache/the-lj-speech-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.99G/2.99G [00:31<00:00, 102MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/tttzof351/ljspeech-meta?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 599k/599k [00:00<00:00, 100MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Data source import complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Hyperparams:\n",
        "  seed = 42\n",
        "\n",
        "  csv_path = \"/content/metadata.csv\"\n",
        "  wav_path = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs\"\n",
        "  save_path = \"/kaggle/working/param\"\n",
        "  log_path = \"/kaggle/working/train_logs\"\n",
        "\n",
        "  save_name = \"SimpleTransfromerTTS.pt\"\n",
        "\n",
        "  # Text transformations params\n",
        "  symbols = [\n",
        "    'EOS', ' ', '!', ',', '-', '.', \\\n",
        "    ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', \\\n",
        "    'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
        "    'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', \\\n",
        "    'â', 'è', 'é', 'ê', 'ü', '’', '“', '”' \\\n",
        "  ]\n",
        "\n",
        "  # Sounds transformations params\n",
        "  sr = 22050\n",
        "  n_fft = 2048\n",
        "  n_stft = int((n_fft//2) + 1)\n",
        "\n",
        "  frame_shift = 0.0125 # seconds\n",
        "  hop_length = int(n_fft/8.0)\n",
        "\n",
        "  frame_length = 0.05 # seconds\n",
        "  win_length = int(n_fft/2.0)\n",
        "\n",
        "  mel_freq = 128\n",
        "  max_mel_time = 1024\n",
        "\n",
        "  max_db = 100\n",
        "  scale_db = 10\n",
        "  ref = 4.0\n",
        "  power = 2.0\n",
        "  norm_db = 10\n",
        "  ampl_multiplier = 10.0\n",
        "  ampl_amin = 1e-10\n",
        "  db_multiplier = 1.0\n",
        "  ampl_ref = 1.0\n",
        "  ampl_power = 1.0\n",
        "\n",
        "  # Model params\n",
        "  text_num_embeddings = 2*len(symbols)\n",
        "  embedding_size = 256\n",
        "  encoder_embedding_size = 512\n",
        "\n",
        "  dim_feedforward = 1024\n",
        "  postnet_embedding_size = 1024\n",
        "\n",
        "  encoder_kernel_size = 3\n",
        "  postnet_kernel_size = 5\n",
        "\n",
        "  # Other\n",
        "  batch_size = 32\n",
        "  grad_clip = 1.0\n",
        "  lr = 2.0 * 1e-4\n",
        "  r_gate = 1.0\n",
        "\n",
        "  step_print = 1000\n",
        "  step_test = 8000\n",
        "  step_save = 8000\n",
        "\n",
        "hp = Hyperparams()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(hp.symbols)\n",
        "  print(len(hp.symbols))\n",
        "\n",
        "\n",
        "hp = Hyperparams()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.657824Z",
          "iopub.execute_input": "2025-06-26T06:51:09.658274Z",
          "iopub.status.idle": "2025-06-26T06:51:09.671791Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.658242Z",
          "shell.execute_reply": "2025-06-26T06:51:09.670558Z"
        },
        "trusted": true,
        "id": "WD6qiySzAmGH",
        "outputId": "b0576bad-2a57-4765-d5c8-5cf231b11a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EOS', ' ', '!', ',', '-', '.', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'â', 'è', 'é', 'ê', 'ü', '’', '“', '”']\n",
            "43\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch\n",
        "symbol_to_id = {\n",
        "  s: i for i, s in enumerate(hp.symbols)\n",
        "}\n",
        "\n",
        "def mask_from_seq_lengths(\n",
        "    sequence_lengths: torch.Tensor,\n",
        "    max_length: int\n",
        ") -> torch.BoolTensor:\n",
        "    \"\"\"\n",
        "    our input was `[2, 2, 3]`, with a `max_length` of 4, we'd return\n",
        "    `[[1, 1, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]]`.\n",
        "    \"\"\"\n",
        "    # (batch_size, max_length)\n",
        "    ones = sequence_lengths.new_ones(sequence_lengths.size(0), max_length)\n",
        "    range_tensor = ones.cumsum(dim=1)\n",
        "    return sequence_lengths.unsqueeze(1) >= range_tensor"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.67353Z",
          "iopub.execute_input": "2025-06-26T06:51:09.673919Z",
          "iopub.status.idle": "2025-06-26T06:51:09.69212Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.673892Z",
          "shell.execute_reply": "2025-06-26T06:51:09.691042Z"
        },
        "trusted": true,
        "id": "GHGHNb4jAmGI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text to Sequence Conversion\n",
        "\n",
        "* **Purpose**: To convert text into a format suitable for input into a neural network.\n",
        "* **Input**: A string of text.\n",
        "* **Output**: A tensor of integer IDs corresponding to the symbols in the text."
      ],
      "metadata": {
        "id": "yk2XiE2qAmGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "symbol_to_id = {\n",
        "  s: i for i, s in enumerate(hp.symbols)\n",
        "}\n",
        "\n",
        "def text_to_seq(text):\n",
        "  text = text.lower()\n",
        "  seq = []\n",
        "  for s in text:\n",
        "    _id = symbol_to_id.get(s, None)\n",
        "    if _id is not None:\n",
        "      seq.append(_id)\n",
        "\n",
        "  seq.append(symbol_to_id[\"EOS\"])\n",
        "\n",
        "  return torch.IntTensor(seq)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(text_to_seq(\"Hello, World\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.693511Z",
          "iopub.execute_input": "2025-06-26T06:51:09.693911Z",
          "iopub.status.idle": "2025-06-26T06:51:09.718883Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.693875Z",
          "shell.execute_reply": "2025-06-26T06:51:09.717673Z"
        },
        "trusted": true,
        "id": "D4HC0q36AmGJ",
        "outputId": "af68ef4e-2b11-4925-fb86-1b23b1a44fc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15, 12, 19, 19, 22,  3,  1, 30, 22, 25, 19, 11,  0], dtype=torch.int32)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.functional import spectrogram\n",
        "\n",
        "\n",
        "spec_transform = torchaudio.transforms.Spectrogram(\n",
        "    n_fft=hp.n_fft,\n",
        "    win_length=hp.win_length,\n",
        "    hop_length=hp.hop_length,\n",
        "    power=hp.power\n",
        ")\n",
        "\n",
        "\n",
        "mel_scale_transform = torchaudio.transforms.MelScale(\n",
        "  n_mels=hp.mel_freq,\n",
        "  sample_rate=hp.sr,\n",
        "  n_stft=hp.n_stft\n",
        ")\n",
        "\n",
        "\n",
        "mel_inverse_transform = torchaudio.transforms.InverseMelScale(\n",
        "  n_mels=hp.mel_freq,\n",
        "  sample_rate=hp.sr,\n",
        "  n_stft=hp.n_stft\n",
        ").cuda()\n",
        "\n",
        "\n",
        "griffnlim_transform = torchaudio.transforms.GriffinLim(\n",
        "    n_fft=hp.n_fft,\n",
        "    win_length=hp.win_length,\n",
        "    hop_length=hp.hop_length\n",
        ").cuda()\n",
        "\n",
        "\n",
        "def norm_mel_spec_db(mel_spec):\n",
        "  mel_spec = ((2.0*mel_spec - hp.min_level_db) / (hp.max_db/hp.norm_db)) - 1.0\n",
        "  mel_spec = torch.clip(mel_spec, -hp.ref*hp.norm_db, hp.ref*hp.norm_db)\n",
        "  return mel_spec\n",
        "\n",
        "\n",
        "def denorm_mel_spec_db(mel_spec):\n",
        "  mel_spec = (((1.0 + mel_spec) * (hp.max_db/hp.norm_db)) + hp.min_level_db) / 2.0\n",
        "  return mel_spec\n",
        "\n",
        "\n",
        "def pow_to_db_mel_spec(mel_spec):\n",
        "  mel_spec = torchaudio.functional.amplitude_to_DB(\n",
        "    mel_spec,\n",
        "    multiplier = hp.ampl_multiplier,\n",
        "    amin = hp.ampl_amin,\n",
        "    db_multiplier = hp.db_multiplier,\n",
        "    top_db = hp.max_db\n",
        "  )\n",
        "  mel_spec = mel_spec/hp.scale_db\n",
        "  return mel_spec\n",
        "\n",
        "\n",
        "def db_to_power_mel_spec(mel_spec):\n",
        "  mel_spec = mel_spec*hp.scale_db\n",
        "  mel_spec = torchaudio.functional.DB_to_amplitude(\n",
        "    mel_spec,\n",
        "    ref=hp.ampl_ref,\n",
        "    power=hp.ampl_power\n",
        "  )\n",
        "  return mel_spec\n",
        "\n",
        "\n",
        "def convert_to_mel_spec(wav):\n",
        "  spec = spec_transform(wav)\n",
        "  mel_spec = mel_scale_transform(spec)\n",
        "  db_mel_spec = pow_to_db_mel_spec(mel_spec)\n",
        "  db_mel_spec = db_mel_spec.squeeze(0)\n",
        "  return db_mel_spec\n",
        "\n",
        "\n",
        "def inverse_mel_spec_to_wav(mel_spec):\n",
        "  power_mel_spec = db_to_power_mel_spec(mel_spec)\n",
        "  spectrogram = mel_inverse_transform(power_mel_spec)\n",
        "  pseudo_wav = griffnlim_transform(spectrogram)\n",
        "  return pseudo_wav\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  wav_path = '/content/LJ001-0007.wav'\n",
        "  waveform, sample_rate = torchaudio.load(wav_path, normalize=True)\n",
        "  mel_spec = convert_to_mel_spec(waveform)\n",
        "  print(\"mel_spec:\", mel_spec.shape)\n",
        "\n",
        "  pseudo_wav = inverse_mel_spec_to_wav(mel_spec.cuda())\n",
        "  print(\"pseudo_wav:\", pseudo_wav.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "GN_b8MYGAmGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae236b6-1cb4-40a1-cadf-8c1dd0a06654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mel_spec: torch.Size([128, 723])\n",
            "pseudo_wav: torch.Size([184832])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "symbol_to_id = {\n",
        "  s: i for i, s in enumerate(hp.symbols)\n",
        "}\n",
        "\n",
        "def text_to_seq(text):\n",
        "  text = text.lower()\n",
        "  seq = []\n",
        "  for s in text:\n",
        "    _id = symbol_to_id.get(s, None)\n",
        "    if _id is not None:\n",
        "      seq.append(_id)\n",
        "\n",
        "  seq.append(symbol_to_id[\"EOS\"])\n",
        "\n",
        "  return torch.IntTensor(seq)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(text_to_seq(\"Hello, World\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.801705Z",
          "iopub.status.idle": "2025-06-26T06:51:09.803204Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.802769Z",
          "shell.execute_reply": "2025-06-26T06:51:09.802795Z"
        },
        "trusted": true,
        "id": "MWPhsHfSAmGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9437112c-5b0f-4abf-a5bb-742d9818cced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15, 12, 19, 19, 22,  3,  1, 30, 22, 25, 19, 11,  0], dtype=torch.int32)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "\n",
        "class TextMelDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    A custom Dataset for loading text and mel-spectrogram pairs.\n",
        "\n",
        "    This dataset loads text and audio data, converts audio to mel-spectrograms,\n",
        "    and caches the results for faster subsequent access.\n",
        "\n",
        "    Attributes:\n",
        "        df (pandas.DataFrame): DataFrame containing metadata about the dataset.\n",
        "        cache (dict): A cache to store processed items.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        \"\"\"\n",
        "        Initialize the dataset.\n",
        "\n",
        "        Args:\n",
        "            df (pandas.DataFrame): DataFrame containing 'wav' and 'text_norm' columns.\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.cache = {}\n",
        "\n",
        "    def get_item(self, row):\n",
        "        \"\"\"\n",
        "        Process a single row of the dataset.\n",
        "\n",
        "        Args:\n",
        "            row (pandas.Series): A row from the dataset DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Processed (text, mel-spectrogram) pair.\n",
        "        \"\"\"\n",
        "        wav_id = row[\"wav\"]\n",
        "        wav_path = f\"{hp.wav_path}/{wav_id}.wav\"\n",
        "        text = row[\"text_norm\"]\n",
        "        text = text_to_seq(text)\n",
        "        waveform, sample_rate = torchaudio.load(wav_path, normalize=True)\n",
        "        assert sample_rate == hp.sr\n",
        "        mel = convert_to_mel_spec(waveform)\n",
        "        return (text, mel)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Get a single item from the dataset.\n",
        "\n",
        "        This method implements caching to speed up repeated access to the same item.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Processed (text, mel-spectrogram) pair.\n",
        "        \"\"\"\n",
        "        row = self.df.iloc[index]\n",
        "        wav_id = row[\"wav\"]\n",
        "        text_mel = self.cache.get(wav_id)\n",
        "        if text_mel is None:\n",
        "            text_mel = self.get_item(row)\n",
        "            self.cache[wav_id] = text_mel\n",
        "\n",
        "        return text_mel\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Get the total number of items in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of items in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "def text_mel_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Collate function for creating batches of data.\n",
        "\n",
        "    This function pads sequences to a consistent length within each batch.\n",
        "\n",
        "    Args:\n",
        "        batch (list): List of (text, mel-spectrogram) pairs.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Batched and padded tensors (text, text lengths, mel-spectrograms, mel lengths, stop tokens).\n",
        "    \"\"\"\n",
        "    text_length_max = torch.tensor(\n",
        "        [text.shape[-1] for text, _ in batch],\n",
        "        dtype=torch.int32\n",
        "    ).max()\n",
        "    mel_length_max = torch.tensor(\n",
        "        [mel.shape[-1] for _, mel in batch],\n",
        "        dtype=torch.int32\n",
        "    ).max()\n",
        "\n",
        "    text_lengths = []\n",
        "    mel_lengths = []\n",
        "    texts_padded = []\n",
        "    mels_padded = []\n",
        "    for text, mel in batch:\n",
        "        text_length = text.shape[-1]\n",
        "        text_padded = torch.nn.functional.pad(\n",
        "            text,\n",
        "            pad=[0, text_length_max-text_length],\n",
        "            value=0\n",
        "        )\n",
        "        mel_length = mel.shape[-1]\n",
        "        mel_padded = torch.nn.functional.pad(\n",
        "            mel,\n",
        "            pad=[0, mel_length_max-mel_length],\n",
        "            value=0\n",
        "        )\n",
        "        text_lengths.append(text_length)\n",
        "        mel_lengths.append(mel_length)\n",
        "        texts_padded.append(text_padded)\n",
        "        mels_padded.append(mel_padded)\n",
        "    text_lengths = torch.tensor(text_lengths, dtype=torch.int32)\n",
        "    mel_lengths = torch.tensor(mel_lengths, dtype=torch.int32)\n",
        "    texts_padded = torch.stack(texts_padded, 0)\n",
        "    mels_padded = torch.stack(mels_padded, 0).transpose(1, 2)\n",
        "    stop_token_padded = mask_from_seq_lengths(\n",
        "        mel_lengths,\n",
        "        mel_length_max\n",
        "    )\n",
        "    stop_token_padded = (~stop_token_padded).float()\n",
        "    stop_token_padded[:, -1] = 1.0\n",
        "\n",
        "    return texts_padded, \\\n",
        "           text_lengths, \\\n",
        "           mels_padded, \\\n",
        "           mel_lengths, \\\n",
        "           stop_token_padded\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(hp.csv_path)\n",
        "    dataset = TextMelDataset(df)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        num_workers=2,\n",
        "        shuffle=True,\n",
        "        sampler=None,\n",
        "        batch_size=hp.batch_size,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        collate_fn=text_mel_collate_fn\n",
        "    )\n",
        "\n",
        "    def names_shape(names, shape):\n",
        "        \"\"\"\n",
        "        Create a formatted string of tensor names and shapes.\n",
        "\n",
        "        Args:\n",
        "            names (list): List of dimension names.\n",
        "            shape (tuple): Shape of the tensor.\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted string of names and shapes.\n",
        "        \"\"\"\n",
        "        assert len(names) == len(shape)\n",
        "        return \"(\" + \", \".join([f\"{k}={v}\" for k, v in list(zip(names, shape))]) + \")\"\n",
        "\n",
        "    # Example usage and shape printing\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        text_padded, \\\n",
        "        text_lengths, \\\n",
        "        mel_padded, \\\n",
        "        mel_lengths, \\\n",
        "        stop_token_padded = batch\n",
        "        print(f\"=========batch {i}=========\")\n",
        "        print(\"text_padded:\", names_shape([\"N\", \"S\"], text_padded.shape))\n",
        "        print(\"text_lengths:\", names_shape([\"N\"], text_lengths.shape))\n",
        "        print(\"mel_padded:\", names_shape([\"N\", \"TIME\", \"FREQ\"], mel_padded.shape))\n",
        "        print(\"mel_lengths:\", names_shape([\"N\"], mel_lengths.shape))\n",
        "        print(\"stop_token_padded:\", names_shape([\"N\", \"TIME\"], stop_token_padded.shape))\n",
        "        if i > 0:\n",
        "            break\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.805057Z",
          "iopub.status.idle": "2025-06-26T06:51:09.805434Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.805266Z",
          "shell.execute_reply": "2025-06-26T06:51:09.805283Z"
        },
        "trusted": true,
        "id": "DOjdU0XBAmGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "c4beb674-a744-40b2-b4a7-0ab38a6db119"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 5 fields in line 7, saw 7\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-3327089171.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextMelDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     train_loader = torch.utils.data.DataLoader(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 5 fields in line 7, saw 7\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# https://github.com/NVIDIA/tacotron2/blob/master/model.py\n",
        "# https://github.com/NVIDIA/tacotron2/blob/master/layers.py\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Represents a single encoder block in the Transformer architecture.\n",
        "\n",
        "    This block consists of self-attention followed by a feedforward network,\n",
        "    with layer normalization and residual connections.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the EncoderBlock with its layers.\n",
        "        \"\"\"\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.norm_1 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
        "        self.attn = torch.nn.MultiheadAttention(\n",
        "            embed_dim=hp.embedding_size,\n",
        "            num_heads=4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
        "        self.norm_2 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
        "        self.linear_1 = nn.Linear(hp.embedding_size, hp.dim_feedforward)\n",
        "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
        "        self.linear_2 = nn.Linear(hp.dim_feedforward, hp.embedding_size)\n",
        "        self.dropout_3 = torch.nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the EncoderBlock.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor\n",
        "            attn_mask (Tensor, optional): Attention mask\n",
        "            key_padding_mask (Tensor, optional): Key padding mask\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Output tensor after passing through the encoder block\n",
        "        \"\"\"\n",
        "        x_out = self.norm_1(x)\n",
        "        x_out, _ = self.attn(\n",
        "            query=x_out,\n",
        "            key=x_out,\n",
        "            value=x_out,\n",
        "            attn_mask=attn_mask,\n",
        "            key_padding_mask=key_padding_mask\n",
        "        )\n",
        "        x_out = self.dropout_1(x_out)\n",
        "        x = x + x_out\n",
        "\n",
        "        x_out = self.norm_2(x)\n",
        "        x_out = self.linear_1(x_out)\n",
        "        x_out = F.relu(x_out)\n",
        "        x_out = self.dropout_2(x_out)\n",
        "        x_out = self.linear_2(x_out)\n",
        "        x_out = self.dropout_3(x_out)\n",
        "        x = x + x_out\n",
        "\n",
        "        return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Represents a single decoder block in the Transformer architecture.\n",
        "\n",
        "    This block consists of self-attention, encoder-decoder attention, and a feedforward network,\n",
        "    with layer normalization and residual connections.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the DecoderBlock with its layers.\n",
        "        \"\"\"\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.norm_1 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
        "        self.self_attn = torch.nn.MultiheadAttention(\n",
        "            embed_dim=hp.embedding_size,\n",
        "            num_heads=4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_1 = torch.nn.Dropout(0.1)\n",
        "        self.norm_2 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
        "        self.attn = torch.nn.MultiheadAttention(\n",
        "            embed_dim=hp.embedding_size,\n",
        "            num_heads=4,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_2 = torch.nn.Dropout(0.1)\n",
        "        self.norm_3 = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
        "        self.linear_1 = nn.Linear(hp.embedding_size, hp.dim_feedforward)\n",
        "        self.dropout_3 = torch.nn.Dropout(0.1)\n",
        "        self.linear_2 = nn.Linear(hp.dim_feedforward, hp.embedding_size)\n",
        "        self.dropout_4 = torch.nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x, memory, x_attn_mask=None, x_key_padding_mask=None,\n",
        "                memory_attn_mask=None, memory_key_padding_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the DecoderBlock.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor\n",
        "            memory (Tensor): Encoder output\n",
        "            x_attn_mask (Tensor, optional): Self-attention mask\n",
        "            x_key_padding_mask (Tensor, optional): Self-attention key padding mask\n",
        "            memory_attn_mask (Tensor, optional): Encoder-decoder attention mask\n",
        "            memory_key_padding_mask (Tensor, optional): Encoder-decoder key padding mask\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Output tensor after passing through the decoder block\n",
        "        \"\"\"\n",
        "        x_out, _ = self.self_attn(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            attn_mask=x_attn_mask,\n",
        "            key_padding_mask=x_key_padding_mask\n",
        "        )\n",
        "        x_out = self.dropout_1(x_out)\n",
        "        x = self.norm_1(x + x_out)\n",
        "\n",
        "        x_out, _ = self.attn(\n",
        "            query=x,\n",
        "            key=memory,\n",
        "            value=memory,\n",
        "            attn_mask=memory_attn_mask,\n",
        "            key_padding_mask=memory_key_padding_mask\n",
        "        )\n",
        "        x_out = self.dropout_2(x_out)\n",
        "        x = self.norm_2(x + x_out)\n",
        "\n",
        "        x_out = self.linear_1(x)\n",
        "        x_out = F.relu(x_out)\n",
        "        x_out = self.dropout_3(x_out)\n",
        "        x_out = self.linear_2(x_out)\n",
        "        x_out = self.dropout_4(x_out)\n",
        "        x = self.norm_3(x + x_out)\n",
        "\n",
        "        return x\n",
        "\n",
        "class EncoderPreNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder pre-network that processes input text before the main encoder.\n",
        "\n",
        "    This network applies embedding, linear transformations, and convolutional layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the EncoderPreNet with its layers.\n",
        "        \"\"\"\n",
        "        super(EncoderPreNet, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=hp.text_num_embeddings,\n",
        "            embedding_dim=hp.encoder_embedding_size\n",
        "        )\n",
        "        self.linear_1 = nn.Linear(hp.encoder_embedding_size, hp.encoder_embedding_size)\n",
        "        self.linear_2 = nn.Linear(hp.encoder_embedding_size, hp.embedding_size)\n",
        "        self.conv_1 = nn.Conv1d(\n",
        "            hp.encoder_embedding_size,\n",
        "            hp.encoder_embedding_size,\n",
        "            kernel_size=hp.encoder_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.encoder_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_1 = nn.BatchNorm1d(hp.encoder_embedding_size)\n",
        "        self.dropout_1 = torch.nn.Dropout(0.5)\n",
        "        self.conv_2 = nn.Conv1d(\n",
        "            hp.encoder_embedding_size,\n",
        "            hp.encoder_embedding_size,\n",
        "            kernel_size=hp.encoder_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.encoder_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_2 = nn.BatchNorm1d(hp.encoder_embedding_size)\n",
        "        self.dropout_2 = torch.nn.Dropout(0.5)\n",
        "        self.conv_3 = nn.Conv1d(\n",
        "            hp.encoder_embedding_size,\n",
        "            hp.encoder_embedding_size,\n",
        "            kernel_size=hp.encoder_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.encoder_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_3 = nn.BatchNorm1d(hp.encoder_embedding_size)\n",
        "        self.dropout_3 = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, text):\n",
        "        \"\"\"\n",
        "        Forward pass of the EncoderPreNet.\n",
        "\n",
        "        Args:\n",
        "            text (Tensor): Input text tensor\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Processed text tensor\n",
        "        \"\"\"\n",
        "        x = self.embedding(text) # (N, S, E)\n",
        "        x = self.linear_1(x)\n",
        "        x = x.transpose(2, 1) # (N, E, S)\n",
        "        x = self.conv_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.bn_3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout_3(x)\n",
        "        x = x.transpose(1, 2) # (N, S, E)\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "class PostNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Post-network that refines the output of the decoder.\n",
        "\n",
        "    This network applies a series of convolutional layers to the mel spectrogram.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the PostNet with its layers.\n",
        "        \"\"\"\n",
        "        super(PostNet, self).__init__()\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(\n",
        "            hp.mel_freq,\n",
        "            hp.postnet_embedding_size,\n",
        "            kernel_size=hp.postnet_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.postnet_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_1 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
        "        self.dropout_1 = torch.nn.Dropout(0.5)\n",
        "        self.conv_2 = nn.Conv1d(\n",
        "            hp.postnet_embedding_size,\n",
        "            hp.postnet_embedding_size,\n",
        "            kernel_size=hp.postnet_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.postnet_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_2 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
        "        self.dropout_2 = torch.nn.Dropout(0.5)\n",
        "        self.conv_3 = nn.Conv1d(\n",
        "            hp.postnet_embedding_size,\n",
        "            hp.postnet_embedding_size,\n",
        "            kernel_size=hp.postnet_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.postnet_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_3 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
        "        self.dropout_3 = torch.nn.Dropout(0.5)\n",
        "        self.conv_4 = nn.Conv1d(\n",
        "            hp.postnet_embedding_size,\n",
        "            hp.postnet_embedding_size,\n",
        "            kernel_size=hp.postnet_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.postnet_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_4 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
        "        self.dropout_4 = torch.nn.Dropout(0.5)\n",
        "        self.conv_5 = nn.Conv1d(\n",
        "            hp.postnet_embedding_size,\n",
        "            hp.postnet_embedding_size,\n",
        "            kernel_size=hp.postnet_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.postnet_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_5 = nn.BatchNorm1d(hp.postnet_embedding_size)\n",
        "        self.dropout_5 = torch.nn.Dropout(0.5)\n",
        "        self.conv_6 = nn.Conv1d(\n",
        "            hp.postnet_embedding_size,\n",
        "            hp.mel_freq,\n",
        "            kernel_size=hp.postnet_kernel_size,\n",
        "            stride=1,\n",
        "            padding=int((hp.postnet_kernel_size - 1) / 2),\n",
        "            dilation=1\n",
        "        )\n",
        "        self.bn_6 = nn.BatchNorm1d(hp.mel_freq)\n",
        "        self.dropout_6 = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the PostNet.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input mel spectrogram\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Refined mel spectrogram\n",
        "        \"\"\"\n",
        "        x = x.transpose(2, 1) # (N, FREQ, TIME)\n",
        "        x = self.conv_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout_1(x) # (N, POSNET_DIM, TIME)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout_2(x) # (N, POSNET_DIM, TIME)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.bn_3(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout_3(x) # (N, POSNET_DIM, TIME)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.bn_4(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout_4(x) # (N, POSNET_DIM, TIME)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.bn_5(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.dropout_5(x) # (N, POSNET_DIM, TIME)\n",
        "        x = self.conv_6(x)\n",
        "        x = self.bn_6(x)\n",
        "        x = self.dropout_6(x) # (N, FREQ, TIME)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class DecoderPreNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder pre-network that processes mel spectrograms before the main decoder.\n",
        "\n",
        "    This network applies linear transformations with dropout.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the DecoderPreNet with its layers.\n",
        "        \"\"\"\n",
        "        super(DecoderPreNet, self).__init__()\n",
        "        self.linear_1 = nn.Linear(hp.mel_freq, hp.embedding_size)\n",
        "        self.linear_2 = nn.Linear(hp.embedding_size, hp.embedding_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the DecoderPreNet.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input mel spectrogram\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Processed mel spectrogram\n",
        "        \"\"\"\n",
        "        x = self.linear_1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=True)\n",
        "        x = self.linear_2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=True)\n",
        "        return x\n",
        "\n",
        "class TransformerTTS(nn.Module):\n",
        "    \"\"\"\n",
        "    Main Transformer-based Text-to-Speech model.\n",
        "\n",
        "    This model combines encoder, decoder, and various auxiliary networks to generate mel spectrograms from text.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, device=\"cuda\"):\n",
        "        \"\"\"\n",
        "        Initialize the TransformerTTS model with its components.\n",
        "\n",
        "        Args:\n",
        "            device (str): Device to run the model on\n",
        "        \"\"\"\n",
        "        super(TransformerTTS, self).__init__()\n",
        "        self.encoder_prenet = EncoderPreNet()\n",
        "        self.decoder_prenet = DecoderPreNet()\n",
        "        self.postnet = PostNet()\n",
        "        self.pos_encoding = nn.Embedding(num_embeddings=hp.max_mel_time, embedding_dim=hp.embedding_size)\n",
        "        self.encoder_block_1 = EncoderBlock()\n",
        "        self.encoder_block_2 = EncoderBlock()\n",
        "        self.encoder_block_3 = EncoderBlock()\n",
        "        self.decoder_block_1 = DecoderBlock()\n",
        "        self.decoder_block_2 = DecoderBlock()\n",
        "        self.decoder_block_3 = DecoderBlock()\n",
        "        self.linear_1 = nn.Linear(hp.embedding_size, hp.mel_freq)\n",
        "        self.linear_2 = nn.Linear(hp.embedding_size, 1)\n",
        "        self.norm_memory = nn.LayerNorm(normalized_shape=hp.embedding_size)\n",
        "\n",
        "    def forward(self, text, text_len, mel, mel_len):\n",
        "        \"\"\"\n",
        "        Forward pass of the TransformerTTS model.\n",
        "\n",
        "        Args:\n",
        "            text (Tensor): Input text tensor\n",
        "            text_len (Tensor): Lengths of input texts\n",
        "            mel (Tensor): Target mel spectrogram\n",
        "            mel_len (Tensor): Lengths of target mel spectrograms\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Tensor, Tensor, Tensor]: Predicted mel spectrogram (post-net),\n",
        "                                           predicted mel spectrogram (pre-net),\n",
        "                                           stop token predictions\n",
        "        \"\"\"\n",
        "        N = text.shape[0]\n",
        "        S = text.shape[1]\n",
        "        TIME = mel.shape[1]\n",
        "\n",
        "        # Create masks\n",
        "        self.src_key_padding_mask = torch.zeros((N, S), device=text.device).masked_fill(\n",
        "            ~mask_from_seq_lengths(text_len, max_length=S), float(\"-inf\")\n",
        "        )\n",
        "        self.src_mask = torch.zeros((S, S), device=text.device).masked_fill(\n",
        "            torch.triu(torch.full((S, S), True, dtype=torch.bool), diagonal=1).to(text.device),\n",
        "            float(\"-inf\")\n",
        "        )\n",
        "        self.tgt_key_padding_mask = torch.zeros((N, TIME), device=mel.device).masked_fill(\n",
        "            ~mask_from_seq_lengths(mel_len, max_length=TIME), float(\"-inf\")\n",
        "        )\n",
        "        self.tgt_mask = torch.zeros((TIME, TIME), device=mel.device).masked_fill(\n",
        "            torch.triu(torch.full((TIME, TIME), True, device=mel.device, dtype=torch.bool), diagonal=1),\n",
        "            float(\"-inf\")\n",
        "        )\n",
        "        self.memory_mask = torch.zeros((TIME, S), device=mel.device).masked_fill(\n",
        "            torch.triu(torch.full((TIME, S), True, device=mel.device, dtype=torch.bool), diagonal=1),\n",
        "            float(\"-inf\")\n",
        "        )\n",
        "\n",
        "        # Encoder\n",
        "        text_x = self.encoder_prenet(text)\n",
        "        pos_codes = self.pos_encoding(torch.arange(hp.max_mel_time).to(mel.device))\n",
        "        S = text_x.shape[1]\n",
        "        text_x = text_x + pos_codes[:S]\n",
        "        text_x = self.encoder_block_1(text_x, attn_mask=self.src_mask, key_padding_mask=self.src_key_padding_mask)\n",
        "        text_x = self.encoder_block_2(text_x, attn_mask=self.src_mask, key_padding_mask=self.src_key_padding_mask)\n",
        "        text_x = self.encoder_block_3(text_x, attn_mask=self.src_mask, key_padding_mask=self.src_key_padding_mask)\n",
        "        text_x = self.norm_memory(text_x)\n",
        "\n",
        "        # Decoder\n",
        "        mel_x = self.decoder_prenet(mel)\n",
        "        mel_x = mel_x + pos_codes[:TIME]\n",
        "        mel_x = self.decoder_block_1(x=mel_x, memory=text_x, x_attn_mask=self.tgt_mask,\n",
        "                                     x_key_padding_mask=self.tgt_key_padding_mask,\n",
        "                                     memory_attn_mask=self.memory_mask,\n",
        "                                     memory_key_padding_mask=self.src_key_padding_mask)\n",
        "        mel_x = self.decoder_block_2(x=mel_x, memory=text_x, x_attn_mask=self.tgt_mask,\n",
        "                                     x_key_padding_mask=self.tgt_key_padding_mask,\n",
        "                                     memory_attn_mask=self.memory_mask,\n",
        "                                     memory_key_padding_mask=self.src_key_padding_mask)\n",
        "        mel_x = self.decoder_block_3(x=mel_x, memory=text_x, x_attn_mask=self.tgt_mask,\n",
        "                                     x_key_padding_mask=self.tgt_key_padding_mask,\n",
        "                                     memory_attn_mask=self.memory_mask,\n",
        "                                     memory_key_padding_mask=self.src_key_padding_mask)\n",
        "\n",
        "        # Output processing\n",
        "        mel_linear = self.linear_1(mel_x)\n",
        "        mel_postnet = self.postnet(mel_linear)\n",
        "        mel_postnet = mel_linear + mel_postnet\n",
        "        stop_token = self.linear_2(mel_x)\n",
        "\n",
        "        # Masking\n",
        "        bool_mel_mask = self.tgt_key_padding_mask.ne(0).unsqueeze(-1).repeat(1, 1, hp.mel_freq)\n",
        "        mel_linear = mel_linear.masked_fill(bool_mel_mask, 0)\n",
        "        mel_postnet = mel_postnet.masked_fill(bool_mel_mask, 0)\n",
        "        stop_token = stop_token.masked_fill(bool_mel_mask[:, :, 0].unsqueeze(-1), 1e3).squeeze(2)\n",
        "\n",
        "        return mel_postnet, mel_linear, stop_token\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def inference(self, text, max_length=800, stop_token_threshold=0.5, with_tqdm=True):\n",
        "        \"\"\"\n",
        "        Generate mel spectrogram from input text (inference mode).\n",
        "\n",
        "        Args:\n",
        "            text (Tensor): Input text tensor\n",
        "            max_length (int): Maximum length of generated mel spectrogram\n",
        "            stop_token_threshold (float): Threshold for stop token prediction\n",
        "            with_tqdm (bool): Whether to use tqdm progress bar\n",
        "\n",
        "        Returns:\n",
        "            Tuple[Tensor, Tensor]: Generated mel spectrogram, stop token predictions\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        self.train(False)\n",
        "        text_lengths = torch.tensor(text.shape[1]).unsqueeze(0).cuda()\n",
        "        N = 1\n",
        "        SOS = torch.zeros((N, 1, hp.mel_freq), device=\"cuda\")\n",
        "\n",
        "        mel_padded = SOS\n",
        "        mel_lengths = torch.tensor(1).unsqueeze(0).cuda()\n",
        "        stop_token_outputs = torch.FloatTensor([]).to(text.device)\n",
        "\n",
        "        iters = tqdm(range(max_length)) if with_tqdm else range(max_length)\n",
        "\n",
        "        for _ in iters:\n",
        "            mel_postnet, mel_linear, stop_token = self(text, text_lengths, mel_padded, mel_lengths)\n",
        "            mel_padded = torch.cat([mel_padded, mel_postnet[:, -1:, :]], dim=1)\n",
        "            if torch.sigmoid(stop_token[:,-1]) > stop_token_threshold:\n",
        "                break\n",
        "            else:\n",
        "                stop_token_outputs = torch.cat([stop_token_outputs, stop_token[:,-1:]], dim=1)\n",
        "                mel_lengths = torch.tensor(mel_padded.shape[1]).unsqueeze(0).cuda()\n",
        "\n",
        "        return mel_postnet, stop_token_outputs\n",
        "\n",
        "def test_with_dataloader():\n",
        "    \"\"\"\n",
        "    Test the TransformerTTS model using a DataLoader.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(hp.csv_path)\n",
        "    dataset = TextMelDataset(df)\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        num_workers=1,\n",
        "        shuffle=False,\n",
        "        sampler=None,\n",
        "        batch_size=4,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        collate_fn=text_mel_collate_fn\n",
        "    )\n",
        "\n",
        "    model = TransformerTTS().cuda()\n",
        "\n",
        "    for batch in loader:\n",
        "        text_padded, text_lengths, mel_padded, mel_lengths, stop_token_padded = batch\n",
        "        text_padded = text_padded.cuda()\n",
        "        text_lengths = text_lengths.cuda()\n",
        "        mel_padded = mel_padded.cuda()\n",
        "        mel_lengths = mel_lengths.cuda()\n",
        "        stop_token_padded = stop_token_padded.cuda()\n",
        "\n",
        "        post, mel, stop_token = model(text_padded, text_lengths, mel_padded, mel_lengths)\n",
        "        print(\"post:\", post.shape)\n",
        "        print(\"mel:\", mel.shape)\n",
        "        print(\"stop_token:\", stop_token.shape)\n",
        "        break\n",
        "\n",
        "def test_inference():\n",
        "    \"\"\"\n",
        "    Test the inference method of the TransformerTTS model.\n",
        "    \"\"\"\n",
        "    model = TransformerTTS().cuda()\n",
        "    text = text_to_seq(\"Hello, world.\").unsqueeze(0).cuda()\n",
        "    mel_postnet, stop_token = model.inference(text, stop_token_threshold=1e3)\n",
        "    print(\"mel_postnet:\", mel_postnet.shape)\n",
        "    print(\"stop_token:\", stop_token.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.80758Z",
          "iopub.status.idle": "2025-06-26T06:51:09.807952Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.807775Z",
          "shell.execute_reply": "2025-06-26T06:51:09.807795Z"
        },
        "trusted": true,
        "id": "7mhIjCc1AmGL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TTSLoss(torch.nn.Module):\n",
        "    \"\"\"https://github.com/NVIDIA/tacotron2/blob/master/loss_function.py\"\"\"\n",
        "    def __init__(self):\n",
        "        super(TTSLoss, self).__init__()\n",
        "\n",
        "        self.mse_loss = torch.nn.MSELoss()\n",
        "        self.bce_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        mel_postnet_out,\n",
        "        mel_out,\n",
        "        stop_token_out,\n",
        "        mel_target,\n",
        "        stop_token_target\n",
        "      ):\n",
        "        stop_token_target = stop_token_target.view(-1, 1)\n",
        "\n",
        "        stop_token_out = stop_token_out.view(-1, 1)\n",
        "        mel_loss = self.mse_loss(mel_out, mel_target) + \\\n",
        "            self.mse_loss(mel_postnet_out, mel_target)\n",
        "\n",
        "        stop_token_loss = self.bce_loss(stop_token_out, stop_token_target) * hp.r_gate\n",
        "\n",
        "        return mel_loss + stop_token_loss\n",
        "tts_loss = TTSLoss()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.809261Z",
          "iopub.status.idle": "2025-06-26T06:51:09.809594Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.80944Z",
          "shell.execute_reply": "2025-06-26T06:51:09.809454Z"
        },
        "trusted": true,
        "id": "wCl948NGAmGN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to process each batch and move data to GPU\n",
        "def batch_process(batch):\n",
        "    text_padded, text_lengths, mel_padded, mel_lengths, stop_token_padded = batch\n",
        "\n",
        "    text_padded = text_padded.cuda()\n",
        "    text_lengths = text_lengths.cuda()\n",
        "    mel_padded = mel_padded.cuda()\n",
        "    stop_token_padded = stop_token_padded.cuda()\n",
        "    mel_lengths = mel_lengths.cuda()\n",
        "\n",
        "    N = mel_padded.shape[0]\n",
        "    SOS = torch.zeros((N, 1, hp.mel_freq), device=mel_padded.device)  # Start of sequence\n",
        "\n",
        "    mel_input = torch.cat(\n",
        "        [SOS, mel_padded[:, :-1, :]],  # (N, L, FREQ)\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    return text_padded, text_lengths, mel_padded, mel_lengths, mel_input, stop_token_padded\n",
        "\n",
        "# Function for inference on a single utterance\n",
        "def inference_utterance(model, text):\n",
        "    sequences = text_to_seq(text).unsqueeze(0).cuda()\n",
        "    postnet_mel, stop_token = model.inference(\n",
        "        sequences,\n",
        "        stop_token_threshold=1e5,\n",
        "        with_tqdm=False\n",
        "    )\n",
        "    audio = inverse_mel_spec_to_wav(postnet_mel.detach()[0].T)\n",
        "\n",
        "    fig, ax1 = plt.subplots(1, 1)\n",
        "    ax1.imshow(\n",
        "        postnet_mel[0, :, :].detach().cpu().numpy().T,\n",
        "    )\n",
        "\n",
        "    return audio, fig\n",
        "\n",
        "# Function to calculate the test loss\n",
        "def calculate_test_loss(model, test_loader):\n",
        "    test_loss_mean = 0.0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for test_i, test_batch in enumerate(test_loader):\n",
        "            test_text_padded, test_text_lengths, test_mel_padded, test_mel_lengths, test_mel_input, test_stop_token_padded = batch_process(test_batch)\n",
        "\n",
        "            test_post_mel_out, test_mel_out, test_stop_token_out = model(\n",
        "                test_text_padded,\n",
        "                test_text_lengths,\n",
        "                test_mel_input,\n",
        "                test_mel_lengths\n",
        "            )\n",
        "            test_loss = criterion(\n",
        "                mel_postnet_out=test_post_mel_out,\n",
        "                mel_out=test_mel_out,\n",
        "                stop_token_out=test_stop_token_out,\n",
        "                mel_target=test_mel_padded,\n",
        "                stop_token_target=test_stop_token_padded\n",
        "            )\n",
        "\n",
        "            test_loss_mean += test_loss.item()\n",
        "\n",
        "    test_loss_mean = test_loss_mean / (test_i + 1)\n",
        "    return test_loss_mean\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    torch.manual_seed(hp.seed)\n",
        "\n",
        "    # Load dataset and split into training and testing sets\n",
        "    df = pd.read_csv(hp.csv_path)\n",
        "    train_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=64,\n",
        "        random_state=hp.seed\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        TextMelDataset(train_df),\n",
        "        num_workers=2,\n",
        "        shuffle=True,\n",
        "        sampler=None,\n",
        "        batch_size=hp.batch_size,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        collate_fn=text_mel_collate_fn\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        TextMelDataset(test_df),\n",
        "        num_workers=2,\n",
        "        shuffle=True,\n",
        "        sampler=None,\n",
        "        batch_size=8,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        collate_fn=text_mel_collate_fn\n",
        "    )\n",
        "\n",
        "    train_saved_path = '/kaggle/working/train/model'\n",
        "    test_saved_path = '/kaggle/working/test/model'\n",
        "\n",
        "    print(\"train_saved_path:\", train_saved_path)\n",
        "    print(\"test_saved_path:\", test_saved_path)\n",
        "\n",
        "    logger = SummaryWriter(hp.log_path)\n",
        "    criterion = TTSLoss().cuda()\n",
        "    model = TransformerTTS().cuda()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=hp.lr)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    best_test_loss_mean = float(\"inf\")\n",
        "    best_train_loss_mean = float(\"inf\")\n",
        "\n",
        "    train_loss_mean = 0.0\n",
        "    epoch = 0\n",
        "    i = 0\n",
        "\n",
        "    # Load the model if checkpoint exists\n",
        "    if os.path.isfile(train_saved_path):\n",
        "        state = torch.load(train_saved_path)\n",
        "        state_model = state[\"model\"]\n",
        "        state_optimizer = state[\"optimizer\"]\n",
        "\n",
        "        i = state[\"i\"] + 1\n",
        "        best_test_loss_mean = state.get(\"test_loss\", float(\"inf\"))\n",
        "        best_train_loss_mean = state.get(\"train_loss\", float(\"inf\"))\n",
        "\n",
        "        model.load_state_dict(state_model)\n",
        "        optimizer.load_state_dict(state_optimizer)\n",
        "\n",
        "        print(f\"Load: {i}; test_loss: {np.round(best_test_loss_mean, 5)}; train_loss: {np.round(best_train_loss_mean, 5)}\")\n",
        "    else:\n",
        "        print(\"Start from zero!\")\n",
        "\n",
        "    start_time_sec = time.time()\n",
        "\n",
        "    num_epochs = 1  # Number of epochs to train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_samples = 0\n",
        "\n",
        "        # Add tqdm progress bar\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
        "        for batch in pbar:\n",
        "            text_padded, text_lengths, mel_padded, mel_lengths, mel_input, stop_token_padded = batch_process(batch)\n",
        "\n",
        "            model.train(True)\n",
        "            model.zero_grad()\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                post_mel_out, mel_out, stop_token_out = model(\n",
        "                    text_padded,\n",
        "                    text_lengths,\n",
        "                    mel_input,\n",
        "                    mel_lengths\n",
        "                )\n",
        "                loss = criterion(\n",
        "                    mel_postnet_out=post_mel_out,\n",
        "                    mel_out=mel_out,\n",
        "                    stop_token_out=stop_token_out,\n",
        "                    mel_target=mel_padded,\n",
        "                    stop_token_target=stop_token_padded\n",
        "                )\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), hp.grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss_mean += loss.item()\n",
        "            epoch_train_loss += loss.item() * text_padded.size(0)\n",
        "            epoch_train_samples += text_padded.size(0)\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.5f}\"})\n",
        "\n",
        "            if i != 0 and i % hp.step_print == 0:\n",
        "                train_loss_mean = train_loss_mean / hp.step_print\n",
        "                logger.add_scalar(\"Loss/train_loss\", train_loss_mean, global_step=i)\n",
        "\n",
        "                if i % hp.step_test == 0:\n",
        "                    test_loss_mean = calculate_test_loss(model, test_loader)\n",
        "                    audio, fig = inference_utterance(model, \"Hello, World.\")\n",
        "\n",
        "                    logger.add_scalar(\"Loss/test_loss\", test_loss_mean, global_step=i)\n",
        "                    logger.add_figure(f\"Img/img_{i}\", fig, global_step=i)\n",
        "                    logger.add_audio(f\"Utterance/audio_{i}\", audio, sample_rate=hp.sr, global_step=i)\n",
        "\n",
        "                    print(f\"{epoch}-{i}) Test loss: {np.round(test_loss_mean, 5)}\")\n",
        "\n",
        "                    if i % hp.step_save == 0:\n",
        "                        is_best_train = train_loss_mean < best_train_loss_mean\n",
        "                        is_best_test = test_loss_mean < best_test_loss_mean\n",
        "\n",
        "                        state = {\n",
        "                            \"model\": model.state_dict(),\n",
        "                            \"optimizer\": optimizer.state_dict(),\n",
        "                            \"i\": i,\n",
        "                            \"test_loss\": test_loss_mean,\n",
        "                            \"train_loss\": train_loss_mean\n",
        "                        }\n",
        "\n",
        "                        if is_best_train:\n",
        "                            print(f\"{epoch}-{i}) Save best train\")\n",
        "                            torch.save(state, train_saved_path)\n",
        "                            best_train_loss_mean = train_loss_mean\n",
        "\n",
        "                        if is_best_test:\n",
        "                            print(f\"{epoch}-{i}) Save best test\")\n",
        "                            torch.save(state, test_saved_path)\n",
        "                            best_test_loss_mean = test_loss_mean\n",
        "\n",
        "                end_time_sec = time.time()\n",
        "                time_sec = np.round(end_time_sec - start_time_sec, 3)\n",
        "                start_time_sec = end_time_sec\n",
        "\n",
        "                print(f\"{epoch}-{i}) Train loss: {np.round(train_loss_mean, 5)}; Duration: {time_sec} sec.\")\n",
        "                train_loss_mean = 0.0\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        # Calculate epoch train MSE\n",
        "        epoch_train_mse = epoch_train_loss / epoch_train_samples\n",
        "\n",
        "        # Calculate epoch test MSE\n",
        "        test_loss_mean = calculate_test_loss(model, test_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch} completed:\")\n",
        "        print(f\"  Train MSE: {epoch_train_mse:.5f}\")\n",
        "        print(f\"  Test MSE: {test_loss_mean:.5f}\")\n",
        "\n",
        "        # Log epoch metrics\n",
        "        logger.add_scalar(\"Epoch/train_mse\", epoch_train_mse, global_step=epoch)\n",
        "        logger.add_scalar(\"Epoch/test_mse\", test_loss_mean, global_step=epoch)\n",
        "\n",
        "        epoch += 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:09.858271Z",
          "iopub.execute_input": "2025-06-26T06:51:09.858635Z",
          "iopub.status.idle": "2025-06-26T06:51:25.792894Z",
          "shell.execute_reply.started": "2025-06-26T06:51:09.858607Z",
          "shell.execute_reply": "2025-06-26T06:51:25.791312Z"
        },
        "trusted": true,
        "id": "-6dV_lKkAmGO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model state dictionary\n",
        "torch.save(model.state_dict(), 'model.pt')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:25.793919Z",
          "iopub.status.idle": "2025-06-26T06:51:25.794362Z",
          "shell.execute_reply.started": "2025-06-26T06:51:25.794185Z",
          "shell.execute_reply": "2025-06-26T06:51:25.794201Z"
        },
        "trusted": true,
        "id": "QPU4cuKyAmGP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pydub\n",
        "\n",
        "def write_mp3(\n",
        "  x,\n",
        "  f=\"audio.mp3\",\n",
        "  sr=hp.sr,\n",
        "  normalized=True\n",
        "):\n",
        "  \"\"\"numpy array to MP3\"\"\"\n",
        "  channels = 2 if (x.ndim == 2 and x.shape[1] == 2) else 1\n",
        "  if normalized:  # normalized array - each item should be a float in [-1, 1)\n",
        "      y = np.int16(x * 2 ** 15)\n",
        "  else:\n",
        "      y = np.int16(x)\n",
        "  song = pydub.AudioSegment(y.tobytes(), frame_rate=sr, sample_width=2, channels=channels)\n",
        "  song.export(f, format=\"mp3\", bitrate=\"320k\")\n",
        "\n",
        "train_saved_path = \"/kaggle/input/model-tts/train_SimpleTransfromerTTS.pt\"\n",
        "state = torch.load(train_saved_path)\n",
        "model = TransformerTTS().cuda()\n",
        "model.load_state_dict(state[\"model\"])\n",
        "\n",
        "text = \"Onece upon a time there was king and a queen\"\n",
        "name_file = \"hello_world.mp3\"\n",
        "\n",
        "\n",
        "postnet_mel, gate = model.inference(\n",
        "  text_to_seq(text).unsqueeze(0).cuda(),\n",
        "stop_token_threshold=1e-5,\n",
        "  with_tqdm = False\n",
        ")\n",
        "\n",
        "audio = inverse_mel_spec_to_wav(postnet_mel.detach()[0].T)\n",
        "\n",
        "plt.plot(\n",
        "    torch.sigmoid(gate[0, :]).detach().cpu().numpy()\n",
        ")\n",
        "\n",
        "write_mp3(\n",
        "    audio.detach().cpu().numpy(),\n",
        "    name_file\n",
        ")\n",
        "\n",
        "IPython.display.Audio(\n",
        "    audio.detach().cpu().numpy(),\n",
        "    rate=hp.sr\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-26T06:51:25.795708Z",
          "iopub.status.idle": "2025-06-26T06:51:25.796088Z",
          "shell.execute_reply.started": "2025-06-26T06:51:25.795888Z",
          "shell.execute_reply": "2025-06-26T06:51:25.795903Z"
        },
        "trusted": true,
        "id": "KUgJFwhoAmGP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "mJ2ZHU5NAmGP"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}